{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28600232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c7c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") # Bypass HF warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "764b0078",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CopiumDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=128)\n",
    "        return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'labels': torch.tensor(label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4906e03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /content\n",
      "Files here: ['.config', 'sample_data']\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "train-balanced-sarcasm.csv not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2302573650.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Current directory: {os.getcwd()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Files here: {os.listdir()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train-balanced-sarcasm.csv not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mdf_sarcasm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: train-balanced-sarcasm.csv not found"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "possible_paths = [\n",
    "    'train-balanced-sarcasm.csv',\n",
    "    '/content/train-balanced-sarcasm.csv',\n",
    "    '/content/drive/MyDrive/train-balanced-sarcasm.csv',\n",
    "    '../cloud/train-balanced-sarcasm.csv'\n",
    "]\n",
    "\n",
    "csv_path = None\n",
    "for path in possible_paths:\n",
    "    if os.path.exists(path):\n",
    "        csv_path = path\n",
    "        print(f\"Found file at: {path}\")\n",
    "        break\n",
    "\n",
    "if csv_path is None:\n",
    "    print(f\"Current directory: {os.getcwd()}\")\n",
    "    print(f\"Files here: {os.listdir()}\")\n",
    "    raise FileNotFoundError(\"train-balanced-sarcasm.csv not found\")\n",
    "\n",
    "df_sarcasm = pd.read_csv(csv_path)\n",
    "\n",
    "copium_patterns = [\n",
    "    r\"\\bit'?s? fine\\b\",\n",
    "    r\"\\bi'?m? (not even |totally )?(mad|upset|bothered)\",\n",
    "    r\"\\bwhatever\\b\",\n",
    "    r\"\\bdidn'?t (even )?(want|need|care)\",\n",
    "    r\"\\bdoesn'?t (even )?(matter|bother)\",\n",
    "    r\"\\bi'?m? over it\\b\",\n",
    "    r\"\\bwho cares\\b\",\n",
    "    r\"\\bnot like i (wanted|needed|cared)\",\n",
    "    r\"\\bi (guess|suppose) (it'?s?|that'?s?) (ok|fine|whatever)\",\n",
    "    r\"\\bcould be worse\\b\",\n",
    "    r\"\\bat least\\b\",\n",
    "    r\"\\bi'?ll? (just |)be fine\\b\",\n",
    "    r\"\\b(anyway|anyways),? (it'?s?|that'?s?) (ok|fine)\",\n",
    "    r\"\\bno big deal\\b\",\n",
    "    r\"\\bnot that (great|good|bad) anyway\",\n",
    "    r\"\\bprobably (for the best|better this way)\",\n",
    "    r\"\\bi'?m? (totally |)okay with (this|that|it)\",\n",
    "    r\"\\bthis is fine\\b\",\n",
    "    r\"\\beverything is fine\\b\",\n",
    "    r\"\\b(lol|lmao|haha),? (it'?s?|i'?m?) (fine|ok|okay)\",\n",
    "]\n",
    "\n",
    "combined_pattern = '|'.join(copium_patterns)\n",
    "\n",
    "df_sarcasm['comment'] = df_sarcasm['comment'].fillna('')\n",
    "df_sarcasm['is_copium'] = df_sarcasm['comment'].str.lower().str.contains(combined_pattern, regex=True)\n",
    "\n",
    "df_copium = df_sarcasm[df_sarcasm['is_copium'] == True][['comment']].copy()\n",
    "df_copium['label'] = 0\n",
    "print(f\"Found {len(df_copium)} potential copium samples\")\n",
    "\n",
    "if len(df_copium) < 2500:\n",
    "    templates = [\n",
    "        \"It's fine, I didn't want {} anyway\",\n",
    "        \"Whatever, {} doesn't even matter\",\n",
    "        \"I'm not even mad about {}\",\n",
    "        \"Who cares about {}? Not me\",\n",
    "        \"{} is overrated anyway\",\n",
    "        \"I guess {} wasn't meant to be\",\n",
    "        \"At least I still have {}\",\n",
    "        \"Could be worse than {}\",\n",
    "        \"I'm totally okay with {}\",\n",
    "        \"Not like I needed {} or anything\",\n",
    "    ]\n",
    "    subjects = [\"the promotion\", \"winning\", \"that relationship\", \"the game\", \"my grade\", \n",
    "                \"the job\", \"their opinion\", \"being right\", \"success\", \"approval\",\n",
    "                \"being included\", \"the prize\", \"first place\", \"the match\", \"my rank\"]\n",
    "    \n",
    "    synthetic = []\n",
    "    for template in templates:\n",
    "        for subject in subjects:\n",
    "            synthetic.append({'comment': template.format(subject), 'label': 0})\n",
    "    \n",
    "    df_synthetic = pd.DataFrame(synthetic)\n",
    "    df_copium = pd.concat([df_copium, df_synthetic], ignore_index=True)\n",
    "\n",
    "df_copium = df_copium.head(2500)\n",
    "df_copium = df_copium.rename(columns={'comment': 'text'})\n",
    "\n",
    "df_sarc = df_sarcasm[(df_sarcasm['label'] == 1) & (df_sarcasm['is_copium'] == False)].head(2500)[['comment']].copy()\n",
    "df_sarc['label'] = 1\n",
    "df_sarc = df_sarc.rename(columns={'comment': 'text'})\n",
    "\n",
    "df_sincere = df_sarcasm[df_sarcasm['label'] == 0].head(2500)[['comment']].copy()\n",
    "df_sincere['label'] = 2\n",
    "df_sincere = df_sincere.rename(columns={'comment': 'text'})\n",
    "\n",
    "df = pd.concat([df_copium[['text', 'label']], df_sarc, df_sincere], ignore_index=True)\n",
    "df = df.dropna()\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nDataset size: {len(df)}\")\n",
    "print(df['label'].value_counts())\n",
    "print(\"\\nSample copium texts:\")\n",
    "print(df[df['label'] == 0]['text'].head(5).tolist())\n",
    "\n",
    "texts = df['text'].tolist()\n",
    "labels = df['label'].tolist()\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "train_dataset = CopiumDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = CopiumDataset(val_texts, val_labels, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04646846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=4)\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(3):\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "075b63c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "F1 Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(true_labels, predictions)}')\n",
    "print(f'F1 Score: {f1_score(true_labels, predictions, average=\"weighted\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3110d580",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('copium_model')\n",
    "tokenizer.save_pretrained('copium_model')\n",
    "print(\"Model saved to 'copium_model/' directory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
